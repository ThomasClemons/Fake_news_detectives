{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the column width to view the text message data.\n",
    "pd.set_option('max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pac_model and tfid_vectorizer restored\n"
     ]
    }
   ],
   "source": [
    "# Restore models using pickle\n",
    "\n",
    "# Restore the trained PassiveAggressiveClassifer model\n",
    "pac_model = pickle.load(open('Resources/pa_classfier.pkl', 'rb'))\n",
    "\n",
    "# Restore the TD-IDF vectorizer\n",
    "tfid_vectorizer = pickle.load(open('Resources/tfid_vectorizer.pkl', 'rb'))\n",
    "\n",
    "print(\"pac_model and tfid_vectorizer restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to clean articles by convering all text to lower case, removing unnecessary punctuation,\n",
    "# removing numbers, stopwords, tokenizing, and Lemmatizing the data. \n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    XXXXXXXPredict the spam/ham classification of a given text message using a pre-trained model.\n",
    "\n",
    "    XXXXParameters:\n",
    "    XXXXX- text (str): The text message to be classified.\n",
    "\n",
    "    XXXXXReturns:\n",
    "    XXXXX- str: A message indicating whether the text message is classified as spam or not.\n",
    "\n",
    "    XXXXThis function takes a text message and a pre-trained pipeline model, then predicts the\n",
    "    XXXXspam/ham classification of the text. The result is a message stating whether the text is\n",
    "    XXXXclassified as spam or not.\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Initialize the WordNet lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Join the words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence number like special character well url\n"
     ]
    }
   ],
   "source": [
    "# Test clean_text function to confirm that it works as expected \n",
    "dirty_text = \"This is an example sentence with some numbers like 123, and special characters !@#$, as well as URLs https://www.example.com\"\n",
    "cleaned_text = clean_text(dirty_text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to predict article. \n",
    "def article_prediction(text):\n",
    "    \"\"\"\n",
    "    XXXXXXXPredict the spam/ham classification of a given text message using a pre-trained model.\n",
    "\n",
    "    XXXXParameters:\n",
    "    XXXXX- text (str): The text message to be classified.\n",
    "\n",
    "    XXXXXReturns:\n",
    "    XXXXX- str: A message indicating whether the text message is classified as spam or not.\n",
    "\n",
    "    XXXXThis function takes a text message and a pre-trained pipeline model, then predicts the\n",
    "    XXXXspam/ham classification of the text. The result is a message stating whether the text is\n",
    "    XXXXclassified as spam or not.\n",
    "    \"\"\"\n",
    "    # Clean text string \n",
    "    text_clean = clean_text(text)\n",
    "    print(text_clean)\n",
    "    \n",
    "    # Convert text string to list for the Vectorizer \n",
    "    text_clean = [text_clean]\n",
    "        \n",
    "    # Vectorize text string \n",
    "    text_tfid = tfid_vectorizer.transform(text_clean)\n",
    "    \n",
    "    # Predict Real or Fake \n",
    "    text_prediction = pac_model.predict(text_tfid)[0]\n",
    "    \n",
    "    if text_prediction == 1:\n",
    "        return 'Real'\n",
    "    else:\n",
    "        return 'Fake'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dubai reuters united arab emirate sunday denied report yemen houthi group fired missile toward nuclear plant uae state news agency wam reported twitter account quoted uae emergency crisis management department saying uae possessed missile defense system could deal threat adding albarakah nuclear plant secure eventuality\n",
      "Real\n"
     ]
    }
   ],
   "source": [
    "# Test article_prediction function with Real article to confirm that it works as expected \n",
    "pred_test_text = \"DUBAI (Reuters) - The United Arab Emirates on Sunday denied a report that \\\n",
    "Yemen s Houthi group had fired a missile toward a nuclear plant in the UAE, state news agency \\\n",
    "WAM reported on its Twitter account. It quoted the UAE s emergency and crisis management department \\\n",
    "as saying the UAE possessed a missile defense system that could deal with any such threats and \\\n",
    "adding the al-Barakah nuclear plant was secure against all eventualities.\"\n",
    "\n",
    "pred_test = article_prediction(pred_test_text)\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that measures the sentiment of a sentence using SentimentIntensityAnalyzer\n",
    "def get_sentiment_rating(sentence):\n",
    "    # Create a SentimentIntensityAnalyzer object\n",
    "    vader_sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # The polarity_scores method of SentimentIntensityAnalyzer returns a sentiment dictionary\n",
    "    # that contains positive, negative, neutral, and compound scores.\n",
    "    vader_sentiment_dict = vader_sentiment.polarity_scores(sentence)\n",
    "     \n",
    "    #print(f'The overall sentiment dictionary is: {vader_sentiment_dict}')\n",
    "    #print(f'sentence sentiment is rated {vader_sentiment_dict[\"neg\"]*100}% Negative')\n",
    "    #print(f'sentence sentiment is rated {vader_sentiment_dict[\"neu\"]*100}% Neutral')\n",
    "    #print(f'sentence sentiment is rated {vader_sentiment_dict[\"pos\"]*100}% Positive')\n",
    "\n",
    "    # Determine if sentiment is positive, negative or neutral\n",
    "    if vader_sentiment_dict['compound'] >= 0.05 :\n",
    "        sentiment_rating = 'Positive'\n",
    "    elif vader_sentiment_dict['compound'] <= - 0.05 :\n",
    "        sentiment_rating = 'Negative'\n",
    "    else :\n",
    "        sentiment_rating = 'Neutral'\n",
    "    \n",
    "    #print(f'Sentence Overall is rated {sentiment_rating}')\n",
    "    return sentiment_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test get_sentiment_rating function\n",
    "test_sentence = \"Google is a great place to search for answers when you don't have any!\"\n",
    "test_result = get_sentiment_rating(test_sentence)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test get_sentiment_rating function\n",
    "test_sentence = pred_test_text[:70]\n",
    "test_result = get_sentiment_rating(test_sentence)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new cleaned_text column by applying the clean_text function to the article text \n",
    "#df_merged_articles['cleaned_text'] = df_merged_articles['text'].apply(clean_text)\n",
    "#df_merged_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "#sms_text_df = pd.read_csv('Resources/SMSSpamCollection.csv')\n",
    "#sms_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the sms_classification function with the DataFrame and set the result to the \"text_clf\" variable\n",
    "#text_clf = sms_classification(sms_text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function called `sms_prediction` that takes in the SMS text and predicts the whether the text is \"not spam\" or \"spam\". \n",
    "# The function should return the SMS message, and say whether the text is \"not spam\" or \"spam\".\n",
    "def article_sentiment_prediction(text):\n",
    "    \"\"\"\n",
    "    xxxxxxPredict the spam/ham classification of a given text message using a pre-trained model.\n",
    "\n",
    "    ccccccccParameters:\n",
    "    - text (str): The text message to be classified.\n",
    "\n",
    "    xxxxxxxxxxReturns:\n",
    "    - str: A message indicating whether the text message is classified as spam or not.\n",
    "\n",
    "    xxxxxThis function takes a text message and a pre-trained pipeline model, then predicts the\n",
    "    xxxxxspam/ham classification of the text. The result is a message stating whether the text is\n",
    "    xxxclassified as spam or not.\n",
    "    \"\"\"\n",
    "    # Get sentiment score\n",
    "    text_sentiment = get_sentiment_rating(text)\n",
    "\n",
    "    # Create a variable that will hold the prediction of a new text.\n",
    "    text_prediction = article_prediction(text)\n",
    "    \n",
    "    # Using a conditional if the prediction is \"ham\" return the message:\n",
    "    # f'The text message: \"{text}\", is not spam.' Else, return f'The text message: \"{text}\", is spam.'\n",
    "    #if text_prediction == \"Real\":\n",
    "    #    message = f'Text Sentiment: {text_sentiment};  The text is: {text_prediction}; Text Analyzed: \"{text}\".'\n",
    "    #else:\n",
    "    #    message = f'Text Sentiment: {text_sentiment};  The text is: {text_prediction}; Text Analyzed: \"{text}\".'\n",
    "    message = f'Text Sentiment: {text_sentiment};  The text is: {text_prediction}; Text Analyzed: \"{text}\".'\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dubai reuters united arab emirate sunday denied report yemen houthi group fired missile toward nuclear plant uae state news agency wam reported twitter account quoted uae emergency crisis management department saying uae possessed missile defense system could deal threat adding albarakah nuclear plant secure eventuality\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Text Sentiment: Negative;  The text is: Real; Text Analyzed: \"DUBAI (Reuters) - The United Arab Emirates on Sunday denied a report that Yemen s Houthi group had fired a missile toward a nuclear plant in the UAE, state news agency WAM reported on its Twitter account. It quoted the UAE s emergency and crisis management department as saying the UAE possessed a missile defense system that could deal with any such threats and adding the al-Barakah nuclear plant was secure against all eventualities.\".'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test article_sentiment_prediction function\n",
    "pred_test_text = \"DUBAI (Reuters) - The United Arab Emirates on Sunday denied a report that \\\n",
    "Yemen s Houthi group had fired a missile toward a nuclear plant in the UAE, state news agency \\\n",
    "WAM reported on its Twitter account. It quoted the UAE s emergency and crisis management department \\\n",
    "as saying the UAE possessed a missile defense system that could deal with any such threats and \\\n",
    "adding the al-Barakah nuclear plant was secure against all eventualities.\"\n",
    "test_result = article_sentiment_prediction(pred_test_text)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "washington reuters president donald trump name david kautter acting commissioner u internal revenue service white house said statement thursday kautter assistant secretary treasury tax policy would become acting head federal governmentâs revenue collection service effective nov white house said\n",
      "armed civilian protect defend u military recruitment center muslim terrorist made clear intend target brave men woman defend nation really much ask allow defend themselvescivilians semiautomatic carbine eating chickfila guarding marine whitehouse pictwittercomofvtpsqeg bob owen bob_owens july ht weasel zipper\n"
     ]
    }
   ],
   "source": [
    "# Create a sms_app that takes a textbox for the inputs and has a textbox for the output.  \n",
    "# Povide labels for each textbox. \n",
    "app = gr.Interface(fn=article_sentiment_prediction,\n",
    "                   inputs=gr.Textbox(label=\"What is the text that you want to test?\"), \n",
    "                   outputs=gr.Textbox(label=\"Our app has determined:\"))\n",
    "    \n",
    "# Launch the app.\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "#Close gradio application when done testing\n",
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
