{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c86bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "#import numpy as np\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#import re\n",
    "#import string \n",
    "#import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71de1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set max row and column display\n",
    "pd.options.display.max_rows=None\n",
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95783bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for article CSV files\n",
    "file_part1 = \"Resources/df_merged_articles_clean_part1.csv\"\n",
    "file_part2 = \"Resources/df_merged_articles_clean_part2.csv\"\n",
    "file_part3 = \"Resources/df_merged_articles_clean_part3.csv\"\n",
    "file_part4 = \"Resources/df_merged_articles_clean_part4.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d690eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files have been read in\n"
     ]
    }
   ],
   "source": [
    "# Read the merged article CSV files into DataFrames\n",
    "df_merged_articles_clean_part1 = pd.read_csv(file_part1)\n",
    "df_merged_articles_clean_part2 = pd.read_csv(file_part2)\n",
    "df_merged_articles_clean_part3 = pd.read_csv(file_part3)\n",
    "df_merged_articles_clean_part4 = pd.read_csv(file_part4)\n",
    "print(\"Input files have been read in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe366503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate article CSV files into merged dataframe\n",
    "df_merged_articles_clean = pd.concat([df_merged_articles_clean_part1, df_merged_articles_clean_part2,\n",
    "                                     df_merged_articles_clean_part3, df_merged_articles_clean_part4],\n",
    "                                     ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0b725a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>subject</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>donald trump wish american happy new year leav...</td>\n",
       "      <td>News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>house intelligence committee chairman devin nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>friday revealed former milwaukee sheriff david...</td>\n",
       "      <td>News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>christmas day donald trump announced would bac...</td>\n",
       "      <td>News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>pope francis used annual christmas day message...</td>\n",
       "      <td>News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...   \n",
       "1  House Intelligence Committee Chairman Devin Nu...   \n",
       "2  On Friday, it was revealed that former Milwauk...   \n",
       "3  On Christmas day, Donald Trump announced that ...   \n",
       "4  Pope Francis used his annual Christmas Day mes...   \n",
       "\n",
       "                                        cleaned_text subject  class  \n",
       "0  donald trump wish american happy new year leav...    News      0  \n",
       "1  house intelligence committee chairman devin nu...    News      0  \n",
       "2  friday revealed former milwaukee sheriff david...    News      0  \n",
       "3  christmas day donald trump announced would bac...    News      0  \n",
       "4  pope francis used annual christmas day message...    News      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first 5 rows of df_merged_articles_clean dataframe\n",
    "df_merged_articles_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc431c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44898, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display shape of df_merged_articles_clean dataframe\n",
    "df_merged_articles_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7b2062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44898 entries, 0 to 44897\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         44898 non-null  object\n",
      " 1   text          44898 non-null  object\n",
      " 2   cleaned_text  44182 non-null  object\n",
      " 3   subject       44898 non-null  object\n",
      " 4   class         44898 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display info for of df_merged_articles_clean dataframe\n",
    "df_merged_articles_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4efc3bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   title  \\\n",
      "9358   https://100percentfedup.com/served-roy-moore-v...   \n",
      "10923  TAKE OUR POLL: Who Do You Think President Trum...   \n",
      "11041  Joe Scarborough BERATES Mika Brzezinski Over “...   \n",
      "11190  WATCH TUCKER CARLSON Scorch Sanctuary City May...   \n",
      "11225  MAYOR OF SANCTUARY CITY: Trump Trying To Make ...   \n",
      "\n",
      "                                                    text cleaned_text  \\\n",
      "9358   https://100percentfedup.com/served-roy-moore-v...          NaN   \n",
      "10923                                                             NaN   \n",
      "11041                                                             NaN   \n",
      "11190                                                             NaN   \n",
      "11225                                                             NaN   \n",
      "\n",
      "        subject  class  \n",
      "9358   politics      0  \n",
      "10923  politics      0  \n",
      "11041  politics      0  \n",
      "11190  politics      0  \n",
      "11225  politics      0  \n"
     ]
    }
   ],
   "source": [
    "# Examine df_merged_articles_clean dataframe to determine if null cleaned_text rows should be dropped or not\n",
    "df_null_cleaned_text_rows = df_merged_articles_clean.loc[df_merged_articles_clean['cleaned_text'].isnull()]\n",
    "print(df_null_cleaned_text_rows.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d54982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
      "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
      "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
      "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
      "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
      "\n",
      "                                                text  \\\n",
      "0  Donald Trump just couldn t wish all Americans ...   \n",
      "1  House Intelligence Committee Chairman Devin Nu...   \n",
      "2  On Friday, it was revealed that former Milwauk...   \n",
      "3  On Christmas day, Donald Trump announced that ...   \n",
      "4  Pope Francis used his annual Christmas Day mes...   \n",
      "\n",
      "                                        cleaned_text subject  class  \n",
      "0  donald trump wish american happy new year leav...    News      0  \n",
      "1  house intelligence committee chairman devin nu...    News      0  \n",
      "2  friday revealed former milwaukee sheriff david...    News      0  \n",
      "3  christmas day donald trump announced would bac...    News      0  \n",
      "4  pope francis used annual christmas day message...    News      0  \n",
      "(44182, 5)\n"
     ]
    }
   ],
   "source": [
    "# Rows with null cleaned_text field contain article text that are URLs or blank.\n",
    "# These rows can be deleted with a small impact on the overall row count (rows reduced from 44898 to 44182).\n",
    "df_merged_articles_revised = df_merged_articles_clean.dropna(subset=['cleaned_text'])\n",
    "print(df_merged_articles_revised.head())\n",
    "print(df_merged_articles_revised.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d86c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y for modeling\n",
    "\n",
    "X = df_merged_articles_revised['cleaned_text']\n",
    "y = df_merged_articles_revised['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc9d012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- X_train info ----------\n",
      "(30927,)\n",
      "5669     donald trump slogan make america great fan che...\n",
      "6671     suffering debilitating loss five northeastern ...\n",
      "3655     donald trump throwing twitter tantrum early mo...\n",
      "32530    washington reuters republican presidential can...\n",
      "26492    washington reuters le three month president do...\n",
      "Name: cleaned_text, dtype: object\n",
      "\n",
      "---------- y_train info ----------\n",
      "(30927,)\n",
      "5669     0\n",
      "6671     0\n",
      "3655     0\n",
      "32530    1\n",
      "26492    1\n",
      "Name: class, dtype: int64\n",
      "\n",
      "---------- y_train info ----------\n",
      "(13255,)\n",
      "30774    washington reuters bitter election campaign fi...\n",
      "4012     donald trump petty thinskinned wannabe dictato...\n",
      "7168     walmart become perfect symbol corporate greed ...\n",
      "25307    following statement posted verified twitter ac...\n",
      "7441     atheist group found truly genius way troll chr...\n",
      "Name: cleaned_text, dtype: object\n",
      "\n",
      "---------- y_test info ----------\n",
      "(13255,)\n",
      "30774    1\n",
      "4012     0\n",
      "7168     0\n",
      "25307    1\n",
      "7441     0\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display X and y train and test information\n",
    "print('---------- X_train info ----------')\n",
    "print(X_train.shape)\n",
    "print(X_train.head())\n",
    "print('\\n---------- y_train info ----------')\n",
    "print(y_train.shape)\n",
    "print(y_train.head())\n",
    "print('\\n---------- y_train info ----------')\n",
    "print(X_test.shape)\n",
    "print(X_test.head())\n",
    "print('\\n---------- y_test info ----------')\n",
    "print(y_test.shape)\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff8cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- X_train_tfidf matrix information  --------------------\n",
      "Matrix shape: (30927, 165713)\n",
      "Total number of documents: 30927\n",
      "Total number of unique words (tokens): 165713\n",
      "-------------------- X_test_tfidf matrix information  --------------------\n",
      "Matrix shape: (13255, 165713)\n",
      "Total number of documents: 13255\n",
      "Total number of unique words (tokens): 165713\n"
     ]
    }
   ],
   "source": [
    "# Calculate TF-IDF for article text using TfidfVectorizer()\n",
    "tfid_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_train_tfidf = tfid_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfid_vectorizer.transform(X_test)\n",
    "\n",
    "# Get X_train_tfidf matrix information\n",
    "print('-------------------- X_train_tfidf matrix information  --------------------')\n",
    "print(f\"Matrix shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Total number of documents: {X_train_tfidf.shape[0]}\")\n",
    "print(f\"Total number of unique words (tokens): {X_train_tfidf.shape[1]}\")\n",
    "\n",
    "# Get X_test_tfidf matrix information\n",
    "print('-------------------- X_test_tfidf matrix information  --------------------')\n",
    "print(f\"Matrix shape: {X_test_tfidf.shape}\")\n",
    "print(f\"Total number of documents: {X_test_tfidf.shape[0]}\")\n",
    "print(f\"Total number of unique words (tokens): {X_test_tfidf.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbca8d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9944926442851754\n",
      "Train Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Passive Aggressive Classifier\n",
    "pac_model = PassiveAggressiveClassifier(max_iter=50)\n",
    "\n",
    "# Train the model\n",
    "pac_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make prediction with test data\n",
    "y_pred = pac_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Check prediction with training data\n",
    "y_pred_train = pac_model.predict(X_train_tfidf)\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Train Accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cd41ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      6853\n",
      "           1       0.99      1.00      0.99      6402\n",
      "\n",
      "    accuracy                           0.99     13255\n",
      "   macro avg       0.99      0.99      0.99     13255\n",
      "weighted avg       0.99      0.99      0.99     13255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "pac_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(pac_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a190d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[6811   42]\n",
      " [  31 6371]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "# [True Postives    False Postives]\n",
    "# [False Negative   True Negatives]\n",
    "\n",
    "pac_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(pac_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "263a7f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pac_model and tfid_vectorizer saved\n"
     ]
    }
   ],
   "source": [
    "# Save models using pickle\n",
    "\n",
    "# Save the trained PassiveAggressiveClassifer model\n",
    "pickle.dump(pac_model, open('Resources/pa_classfier.pkl', 'wb'))\n",
    "\n",
    "# Save the TD-IDF vectorizer\n",
    "pickle.dump(tfid_vectorizer, open('Resources/tfid_vectorizer.pkl', 'wb'))\n",
    "\n",
    "print(\"pac_model and tfid_vectorizer saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2831558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, X_test, y_train, y_test files saved\n"
     ]
    }
   ],
   "source": [
    "# Save X_train, X_test, y_train, y_test data files for use in other notebooks, if needed\n",
    "X_train.to_csv('Resources/X_train.csv', index=False)\n",
    "y_train.to_csv('Resources/y_train.csv', index=False)\n",
    "X_test.to_csv('Resources/X_test.csv', index=False)\n",
    "y_test.to_csv('Resources/y_test.csv', index=False)\n",
    "print(\"X_train, X_test, y_train, y_test files saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97c9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
